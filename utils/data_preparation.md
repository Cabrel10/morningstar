---

## üìò `utils/data_preparation.md` ‚Äì Sp√©cification compl√®te

### üîß Objectif G√©n√©ral

#### üöÄ T√©l√©chargement des Donn√©es et Cr√©ation de Dataset
Ajout d'une section expliquant comment utiliser les fonctions pour t√©l√©charger les donn√©es brutes et g√©n√©rer des datasets enrichis. Exemple :
```python
from utils.api_manager import fetch_ohlcv_data, save_data
df = fetch_ohlcv_data('binance', 'BTC/USDT', '1h', '2024-01-01', '2024-12-31')
save_data(df, 'data/raw/btc_usdt_1h.csv')
```

Ce module est responsable de transformer les donn√©es brutes multi-sources en jeux de donn√©es standardis√©s, enrichis, labelis√©s et utilisables directement par les mod√®les. Il agit en interface entre la couche de collecte (`data/raw/`) et les modules de mod√©lisation (`model/`).

---

## üß© Composition du module

### 1. `load_raw_data(file_path: str)`

**But :** Charger un fichier de donn√©es brutes (CSV ou JSON) depuis le chemin sp√©cifi√©. G√®re la lecture, la validation des colonnes minimales et la normalisation du timestamp en UTC.

- **Entr√©es :**
  - `file_path` (str) : Chemin complet vers le fichier brut (ex: `'data/raw/BTC_USDT_1h.csv'`).
- **Sortie :**
  - `Optional[pandas.DataFrame]` : DataFrame contenant les donn√©es brutes avec un index `Timestamp` UTC, ou `None` si une erreur survient (fichier non trouv√©, format invalide, colonnes manquantes, erreur de conversion de timestamp).
- **Validation :**
  - V√©rifie l'existence du fichier.
  - Supporte les formats `.csv` et `.json` (line-delimited).
  - V√©rifie la pr√©sence des colonnes minimales requises : `timestamp`, `open`, `high`, `low`, `close`, `volume`.
  - Convertit la colonne `timestamp` en `datetime` UTC et la d√©finit comme index du DataFrame. G√®re les erreurs de conversion et les fuseaux horaires potentiels.
- **Logs / Prints :**
  - Indique le succ√®s ou l'√©chec du chargement.
  - Pr√©cise les colonnes manquantes si applicable.
  - Signale les erreurs de conversion de timestamp.

---

### 2. `clean_data(df: pd.DataFrame)`

**But :** Nettoyer le DataFrame brut en g√©rant les valeurs manquantes (NaN) et les outliers potentiels.

- **Entr√©es :**
  - `df` (pd.DataFrame) : DataFrame brut issu de `load_raw_data`, avec un index `Timestamp` UTC.
- **Sortie :**
  - `pd.DataFrame` : DataFrame nettoy√©, pr√™t pour l'√©tape de feature engineering.
- **Comportement :**
  - **Gestion des NaN :**
    - Applique `ffill()` (forward fill) sur les colonnes OHLCV pour propager la derni√®re valeur valide.
    - Si des NaN persistent au d√©but, applique `bfill()` (backward fill) ou remplace par 0 pour le volume.
    - Supprime les lignes o√π `close` reste NaN apr√®s imputation.
  - **Gestion des outliers (Exemple simple bas√© sur IQR des rendements) :**
    - Calcule les rendements (`pct_change`).
    - Identifie les valeurs en dehors de l'intervalle interquartile (IQR * 1.5).
    - Logue le nombre d'outliers d√©tect√©s (l'action de correction/suppression est comment√©e dans le code actuel et peut √™tre adapt√©e).
- **Logs / Prints :**
  - Affiche les dimensions avant et apr√®s nettoyage.
  - Indique le nombre de NaNs remplis par colonne (ffill, bfill, 0).
  - Signale le nombre de lignes supprim√©es √† cause de NaNs persistants.
  - Indique le nombre d'outliers d√©tect√©s.

---

### 3. `save_processed_data(df: pd.DataFrame, output_path: str, format: str = 'parquet')`

**But :** Sauvegarder le DataFrame trait√© dans un fichier au format sp√©cifi√© (Parquet par d√©faut).

- **Entr√©es :**
  - `df` (pd.DataFrame) : Le DataFrame (g√©n√©ralement nettoy√© ou enrichi) √† sauvegarder.
  - `output_path` (str) : Chemin complet du fichier de sortie (ex: `'data/processed/BTC_USDT_1h_clean.parquet'`).
  - `format` (str, optionnel) : Format de sortie, 'parquet' ou 'csv'. D√©faut : 'parquet'.
- **Comportement :**
  - Cr√©e le r√©pertoire de sortie s'il n'existe pas.
  - Sauvegarde le DataFrame en utilisant `to_parquet()` ou `to_csv()`.
- **Logs / Prints :**
  - Confirme la cr√©ation du r√©pertoire si n√©cessaire.
  - Indique le succ√®s ou l'√©chec de la sauvegarde et le chemin du fichier.
  - Signale si le format demand√© n'est pas support√©.

---

### 4. `apply_technical_indicators(df)`

**But :** Calculer les indicateurs techniques de base. (Fonctionnalit√© √† impl√©menter par D√©veloppeur B)

- **Entr√©e :** Donn√©es propres
- **Sortie :** `DataFrame` avec colonnes suppl√©mentaires :
  - RSI, MACD, SMA/EMA (5, 20, 50), Bollinger, ATR, ADX, StochRSI, Ichimoku
- **Librairies :**
  - `ta-lib` (ou `pandas-ta` si ta-lib n‚Äôest pas dispo)
- **Param√®tres configurables :**
  - Fen√™tres glissantes (ex. `rsi_window=14`, `sma_window=20`)

---

### 5. `integrate_sentiment_data(market_df, sentiment_df)`

**But :** Fusionner les signaux de sentiment (Reddit, Twitter, news). (Fonctionnalit√© √† impl√©menter par D√©veloppeur B/C)

- **Entr√©es :**
  - Donn√©es de march√© (`market_df`)
  - Donn√©es de sentiment (`sentiment_df`)
- **Sortie :**
  - `DataFrame` enrichi : `sentiment_score`, `buzz_index`, `toxicity_score`
- **M√©thodes de fusion :**
  - Join temporel arrondi √† la minute/heures/jour
  - Moyenne glissante pond√©r√©e par fr√©quence de mention

---

### 6. `generate_labels(df, horizon='15min', type='classification')`

**But :** G√©n√©rer les cibles d‚Äôapprentissage supervis√©. (Fonctionnalit√© √† impl√©menter par D√©veloppeur C)

- **Entr√©e :**
  - Donn√©es enrichies
  - Horizon (15min, 1h, 1d)
  - Type : `classification`, `regression`, `market_regime`
- **Sortie :** DataFrame avec colonnes de labels :
  - `price_change_label`, `volatility_cluster`, `tp_sl_targets`
- **M√©thodes propos√©es :**
  - Classification : changement de prix seuil (e.g., ¬±1%)
  - R√©gimes : KMeans ou HMM sur volatilit√©/volume
  - TP/SL : +2%/-1% √† horizon T ‚Üí cible multi-t√™te

---

### 7. `build_dataset(symbols, freq='15min')`

**But :** Fonction orchestratrice globale. (Fonctionnalit√© √† impl√©menter apr√®s les √©tapes individuelles)

- **√âtapes ex√©cut√©es :**
  1. Charger et nettoyer
  2. Appliquer indicateurs techniques
  3. Fusionner sentiment/news
  4. G√©n√©rer labels
- **Retourne :**
  - `features_df`, `labels_df`, `full_df`
- **Logging structur√© :**
  - Nb. de points par symbole
  - R√©partition des classes
  - Temps de traitement par √©tape

---

## üîÑ Comportement g√©n√©ral attendu

- Compatible multi-actifs (BTC, ETH, altcoins).
- Multi-√©chelles temporelles.
- Con√ßu pour une mise √† jour incr√©mentale quotidienne.
- Modularit√© maximale : chaque √©tape testable seule.

---

## üìå D√©pendances (Module Complet)

```txt
# Pour les fonctions impl√©ment√©es (Dev A):
pandas
numpy
python-dotenv # Bien que non utilis√© directement dans les fonctions, list√© pour le projet

# Pour les √©tapes futures (Dev B & C):
ta-lib (ou pandas-ta)
scikit-learn
# nltk / textblob / transformers (si scoring NLP local)
# Potentiellement d'autres selon les sources de donn√©es (ex: ccxt, newsapi-python)
```

---

## üì° Extensions pr√©vues

- Int√©gration d‚Äôon-chain analytics (avec Coinmetrics / Glassnode).
- Ajout d‚Äôun LLM scoring assistant pour taguer les √©v√©nements financiers.
- Pipeline d‚Äô√©chantillonnage intelligent : s√©lection de fen√™tres de march√© pertinentes (drawdown, rallye, panique).
